{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![WMLE LOGOS](https://github.com/sanjayksau/wmle2024/blob/main/logo3.png?raw=true)\n",
        "\n"
      ],
      "metadata": {
        "id": "GuHE7I0GQ0ev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Machine Learning with German Credit Dataset\n",
        "![ML Pipeline](https://github.com/sanjayksau/wmle2024/blob/main/ml_pipeline.png?raw=true)\n",
        "\n"
      ],
      "metadata": {
        "id": "zd48FIMUHZNP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset Characteristics\n",
        "Dataset: Statlog(German Credit Data) https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data\n",
        "\n",
        "\n",
        "Dataset Characteristics: Multivariate\n",
        "\n",
        "Subject Area: Social Science\n",
        "\n",
        "Associated Tasks: Classification\n",
        "\n",
        "Feature Type: Categorical, Integer\n",
        "\n",
        "Num of Instances: 1000\n",
        "\n",
        "Num of Features: 20\n",
        "\n",
        "# Attribute Information (Dataset Details):\n",
        "- Attribute 1: (qualitative) Status of existing checking account\n",
        "- Attribute 2: (numerical) Duration in month\n",
        "- Attribute 3: (qualitative) Credit history\n",
        "- Attribute 4: (qualitative) Purpose\n",
        "- Attribute 5: (numerical) Credit amount\n",
        "- Attribute 6: (qualitative) Savings account/bonds\n",
        "- Attribute 7: (qualitative) Present employment since\n",
        "- Attribute 8: (numerical) Installment rate in percentage of disposable income\n",
        "- Attribute 9: (qualitative) Personal status and sex\n",
        "- Attribute 10: (qualitative) Other debtors/guarantors\n",
        "- Attribute 11: (numerical) Present residence since\n",
        "- Attribute 12: (qualitative) Property\n",
        "- Attribute 13: (numerical) Age in years\n",
        "- Attribute 14: (qualitative) Other installment plans\n",
        "- Attribute 15: (qualitative) Housing\n",
        "- Attribute 16: (numerical) Number of existing credits at this bank\n",
        "- Attribute 17: (qualitative) Job\n",
        "- Attribute 18: (numerical) Number of people being liable to provide maintenance for\n",
        "- Attribute 19: (qualitative) Telephone\n",
        "- Attribute 20: (qualitative) Foreign worker\n"
      ],
      "metadata": {
        "id": "uZ3vbBzKJyHp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load the German Credit Dataset"
      ],
      "metadata": {
        "id": "8HwB2eIZVLVA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Upload Dataset from  https://archive.ics.uci.edu/static/public/144/data.csv"
      ],
      "metadata": {
        "id": "P4FOwQStYJVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: access dataset from https://archive.ics.uci.edu/static/public/144/data.csv\n"
      ],
      "metadata": {
        "id": "Xh-fSlbiXblN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload Dataset from Google Drive"
      ],
      "metadata": {
        "id": "JSocBFYhYnIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Upload dataset from Google Drive if available\n",
        "#/content/drive/MyDrive/WMLE2024/german_data.csv: change this appropriately\n"
      ],
      "metadata": {
        "id": "rKV_K3R4YmzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload data available on local system"
      ],
      "metadata": {
        "id": "YMHVMNAca2jY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload dataset from local system in colab and read in a DataFrame.\n"
      ],
      "metadata": {
        "id": "K-_wedLabUIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Install ucimlrepo package"
      ],
      "metadata": {
        "id": "-E2Ohv0LHdfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO:  Install ucimlrepo package to fetch UCI datasets easily\n"
      ],
      "metadata": {
        "id": "3NaYf8kcHb1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Fetch dataset here as suggested on https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data\n"
      ],
      "metadata": {
        "id": "bWIHpQDSH9SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#default column names\n",
        "print(X.columns)\n",
        "\n",
        "#Renaming columns with these relatable names.\n",
        "new_feature_names = ['Status_of_existing_checking_account',\n",
        " 'Duration_in_month',\n",
        " 'Credit_history',\n",
        " 'Purpose',\n",
        " 'Credit_amount',\n",
        " 'Savings_account_or_bonds',\n",
        " 'Present_employment_since',\n",
        " 'Installment_rate_in_percentage_of_disposable_income',\n",
        " 'Personal_status_and_sex',\n",
        " 'Other_debtors_or_guarantors',\n",
        " 'Present_residence_since',\n",
        " 'Property',\n",
        " 'Age_in_years',\n",
        " 'Other_installment_plans',\n",
        " 'Housing',\n",
        " 'Number_of_existing_credits_at_this_bank',\n",
        " 'Job',\n",
        " 'Number_of_people_being_liable_to_provide_maintenance_for',\n",
        " 'Telephone',\n",
        " 'foreign_worker']\n",
        "\n",
        "#Update and Verify the updated names\n",
        "X.columns = new_feature_names\n",
        "print()\n",
        "print(X.columns)"
      ],
      "metadata": {
        "id": "HScO238a1f-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exploratory Data Analysis(EDA)\n",
        "In this step, we will perform some basic exploratory data analysis to understand the dataset."
      ],
      "metadata": {
        "id": "8WyzZ1t0IHQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Visualizing the distribution of Numeric Variables"
      ],
      "metadata": {
        "id": "wBbqKbHMIbXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: import matplotlib.pyplot as plt\n",
        "\n",
        "#Identify all numeric columns\n",
        "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "subset = X[num_cols]\n",
        "\n",
        "# Plot histograms of numeric features\n",
        "subset.hist(bins=15, figsize=(15, 10)) #figsize: width and height in inches\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t2lBJ8-eIRWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Age Distribution"
      ],
      "metadata": {
        "id": "kr0M5LT7IWtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Age distribution (Attribute: 'Age_in_years' represents Age in the dataset)\n",
        "#TODO: import libraray seborn as sns\n",
        "\n",
        "sns.histplot(X['Age_in_years'], kde=True)\n",
        "plt.title('Age Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W3kuxVdCIWRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Credit Amount Distribution\n"
      ],
      "metadata": {
        "id": "YQbzdBuiHcce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Plot Credit Amount distribution (Attribute: 'Credit_amount' represents Credit Amount)\n"
      ],
      "metadata": {
        "id": "z1_X2G18Ikvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correlation Heatmap of Numerical Features"
      ],
      "metadata": {
        "id": "gVK65z2mIsOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a correlation matrix of numeric features\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(subset.corr(), annot=True) #annot annotes the correlation values in the heatmap\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TgGfW0A-IpMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preprocessing\n",
        "\n",
        "Before building a machine learning model, it's important to preprocess the data. We will use a pipeline for the transformation."
      ],
      "metadata": {
        "id": "epO5NiaqI3zF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Categorical to Numerical Conversion and Feature Scaling in the Dataset\n"
      ],
      "metadata": {
        "id": "1IgweL2aJBhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Display Dataset information again to verify the different feature datatypes\n"
      ],
      "metadata": {
        "id": "7XJqEu6gnlyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary preprocessing tools\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
        "\n",
        "\n",
        "# Define ColumnTransformer for handling different types of variables\n",
        "#The conversion of Categorical/Qualitative features to oderinal or one-hot needs more careful consideration.\n",
        "#Also Scaling is done just for demonstration, not required here.\n",
        "HybridTransformer = ColumnTransformer([\n",
        "    (\"ordinal\", OrdinalEncoder(), [\"Status_of_existing_checking_account\", \"Credit_history\", \"Savings_account_or_bonds\", \"Present_employment_since\",\n",
        "                                   \"Other_debtors_or_guarantors\", \"Property\", \"Other_installment_plans\", \"Housing\", \"Job\", \"Telephone\", \"foreign_worker\"]),\n",
        "    (\"onehot\", OneHotEncoder(), [\"Purpose\", \"Personal_status_and_sex\"])\n",
        "], remainder=\"passthrough\")\n",
        "\n",
        "# Build pipeline with ColumnTransformer and StandardScaler\n",
        "pipe = Pipeline([\n",
        "    (\"transforming\", HybridTransformer),\n",
        "    (\"scale\", StandardScaler())\n",
        "])\n",
        "\n",
        "\n",
        "#TODO: Transform the data using the pipeline and assign it to X_transformed\n",
        "\n",
        "\n",
        "#TODO: Display the shape of transformed X\n",
        "\n",
        "# TODO: Display pipe\n",
        "\n",
        "\n",
        "# TODO: Display new Feature names\n"
      ],
      "metadata": {
        "id": "xpkvXbBBI2zW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Encode the Target Variable to 0, 1\n"
      ],
      "metadata": {
        "id": "v8KWp5pvJQ2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Label encode the target variable (class 0 and 1)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "y_encoded = LabelEncoder().fit_transform(y) #DataFrame to numpy array\n",
        "\n",
        "#TODO Check the shape of the target variable\n"
      ],
      "metadata": {
        "id": "Un06x4WiJHMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Building (Decision Tree)\n",
        "- Add text to add other classifiers also and emphasize that there are several classifiers availabe and depending on your choice you can go with any model."
      ],
      "metadata": {
        "id": "aAtRSBm4JY3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#TODO: Split the data, Build the Model, Train and Predict\n",
        "# Split the data into train and test sets\n",
        "\n",
        "# Initialize and train the decision tree classifier, max_depth=4\n",
        "\n",
        "\n",
        "# Predict on test data(X_test)\n",
        "\n",
        "\n",
        "# Check the accuracy\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "print(\"Model accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "#TODO: Compute: precision, recall and f1_score.\n"
      ],
      "metadata": {
        "id": "dXC-1xpSJVBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualizing the decision Tree\n"
      ],
      "metadata": {
        "id": "qp348xRxK2HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary function to plot the decision tree\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "# Set figure size for better readability\n",
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "#TODO: Plot the decision tree, max_depth=2\n",
        "plot_tree(clf, max_depth=2, feature_names=pipe[0].get_feature_names_out(), class_names=['Good', 'Bad'], proportion=True, filled=True, rounded=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BmOmY78-Je-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TODO\n",
        "\n",
        "- Change the split criterion to 'entropy', retrain and generate tree again.\n",
        "\n",
        "- The dataset webside mentions cost_matrix. The cost of assigning a 'Bad' risk to a 'Good' one is much less than assigning a 'Good' label to a 'Bad' one.\n",
        "\n",
        "- Implement this agressive assignment for 'Bad' and observe the changes in Decision Tree. use the following to impletment the same.\n",
        "clf = DecisionTreeClassifier(max_depth=4, class_weight={0: 1, 1: 5}) #more favorable towards classifying as bad\n",
        "\n",
        "- Look at the German Credit Dataset again and verify the ordinal/one-hot encoding assigned to categorial variables. Reassign if required, and rerun the pipeline, train the model, evaluate performance and visualize the Decision tree for new results"
      ],
      "metadata": {
        "id": "PRGhnb_B6XFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Try plotting with different max_depth parameter values.\n",
        "#plot_tree(clf, max_depth=2, feature_names=pipe[0].get_feature_names_out(), class_names=['Class 0', 'Class 1'], filled=True, rounded=True)"
      ],
      "metadata": {
        "id": "of_Fl6SdA_Gp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}